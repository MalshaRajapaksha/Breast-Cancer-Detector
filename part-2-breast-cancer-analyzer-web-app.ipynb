{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "eb49344adfa785e154e7f5cd60643298c51ca819"
   },
   "source": [
    "### Part 2 - Metastatic Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "c1e92489350fd6543d60b41cbde9c69f332eb23e"
   },
   "source": [
    "In this section I will create the Metastatic_model. This model will predict whether or not Metastatic cancer tissue is present in histopathologic image  patches.\n",
    "\n",
    "**Dataset** \n",
    "\n",
    "I will use Google histopathologic image patches dataset.\n",
    "\n",
    "The images are in tiff  format. Many web browsers, including Chrome, don't support the tiff format. Thus the web app wil not be able to accept tiff images. Before training, I will convert these images to png format. This will ensure that the model will be trained on images of similar quality to what we expect a user to submit.\n",
    "\n",
    "\n",
    "Results\n",
    "\n",
    "This CNN model will achieve an accuracy and F1 score that is greater than 0.90.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "from numpy.random import seed\n",
    "seed(101)\n",
    "from tensorflow import set_random_seed\n",
    "set_random_seed(101)\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D\n",
    "from tensorflow.keras.layers import Dense, Dropout, Flatten, Activation\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "import os\n",
    "import cv2\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "import itertools\n",
    "import shutil\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "b7bbdd52c81188b8e9c528b88d9fd0da176bf4bc"
   },
   "outputs": [],
   "source": [
    "\n",
    "IMAGE_SIZE = 96\n",
    "IMAGE_CHANNELS = 3\n",
    "\n",
    "SAMPLE_SIZE = 80000 \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "25802a26e4afba8f6dc42754f7f61da4c8cfea5c"
   },
   "source": [
    "### What files are available?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "699bb899bde433ba20fb0d086fa0f33a0f61a250"
   },
   "outputs": [],
   "source": [
    "os.listdir('../input/histopathologic-cancer-detection')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "c24d1662f8bd5fc4d8c57c29449990a3520cd96b"
   },
   "source": [
    "### Labels as per csv file\n",
    "\n",
    "0 = no met tissue<br>\n",
    "1 =   has met tissue. <br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "5a285343c286be191aa827ff9b836b67821176a5"
   },
   "source": [
    "### How many training images are in each folder?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "54461212efed65ac377369a468c80e7d708010f4"
   },
   "outputs": [],
   "source": [
    "\n",
    "print(len(os.listdir('../input/histopathologic-cancer-detection/train')))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "b90854e07d495d9f945a0e40189fd32a0c32bff5"
   },
   "source": [
    "### Create a Dataframe containing all images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "e9c9f40ffab35044641b0dc7d9b18609af1aa25e"
   },
   "outputs": [],
   "source": [
    "df_data = pd.read_csv('../input/histopathologic-cancer-detection/train_labels.csv')\n",
    "\n",
    "df_data = df_data[df_data['id'] != 'dd6dfed324f9fcb6f93f46f32fc800f2ec196be2']\n",
    "\n",
    "df_data = df_data[df_data['id'] != '9369c7278ec8bcc6c880d99194de09fc2bd4efbe']\n",
    "\n",
    "\n",
    "print(df_data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "cfbd53b7f8ea1929952ffed6221b380012618e32"
   },
   "source": [
    "### Check the class distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "e18560bf69d3dfc0c4772e7c79bb119fd2eb634b"
   },
   "outputs": [],
   "source": [
    "df_data['label'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "6efe2e5de99c4bf92079b1a7d0b892d30fc9d518"
   },
   "source": [
    "### Display a random sample of train images  by class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "_uuid": "1c5143f227da4262eafce8cf0210a02c8072fb8e"
   },
   "outputs": [],
   "source": [
    "def draw_category_images(col_name,figure_cols, df, IMAGE_PATH):\n",
    "    \n",
    "    \"\"\"\n",
    "    Give a column in a dataframe,\n",
    "    this function takes a sample of each class and displays that\n",
    "    sample on one row. The sample size is the same as figure_cols which\n",
    "    is the number of columns in the figure.\n",
    "    Because this function takes a random sample, each time the function is run it\n",
    "    displays different images.\n",
    "    \"\"\"\n",
    "    \n",
    "\n",
    "    categories = (df.groupby([col_name])[col_name].nunique()).index\n",
    "    f, ax = plt.subplots(nrows=len(categories),ncols=figure_cols, \n",
    "                         figsize=(4*figure_cols,4*len(categories))) \n",
    "    for i, cat in enumerate(categories):\n",
    "        sample = df[df[col_name]==cat].sample(figure_cols) \n",
    "        for j in range(0,figure_cols):\n",
    "            file=IMAGE_PATH + sample.iloc[j]['id'] + '.tif'\n",
    "            im=cv2.imread(file)\n",
    "            ax[i, j].imshow(im, resample=True, cmap='gray')\n",
    "            ax[i, j].set_title(cat, fontsize=16)  \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "bd38bcfb5839975e4fee9e70b93d42c29c1b5d2e"
   },
   "outputs": [],
   "source": [
    "IMAGE_PATH = '../input/histopathologic-cancer-detection/train/' \n",
    "\n",
    "draw_category_images('label',4, df_data, IMAGE_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "1da4226777aefe65b1bb3430208ea91ea7ca7d9a"
   },
   "source": [
    "### Create the Train and Val Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "547f9f571ee82e20b7647e16ed36de7550046032"
   },
   "outputs": [],
   "source": [
    "df_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "c1150500d2772b7f36cdaa5aa5fd7f0fb4a72628"
   },
   "source": [
    "#### Balance the target distribution\n",
    "I will reduce the number of samples in class 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "270fc18640b552ecc3cb0e1dd3036441db7a4a2b"
   },
   "outputs": [],
   "source": [
    "df_0 = df_data[df_data['label'] == 0].sample(SAMPLE_SIZE, random_state = 101)\n",
    "df_1 = df_data[df_data['label'] == 1].sample(SAMPLE_SIZE, random_state = 101)\n",
    "\n",
    "df_data = pd.concat([df_0, df_1], axis=0).reset_index(drop=True)\n",
    "df_data = shuffle(df_data)\n",
    "\n",
    "df_data['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "a166dec3ef84c66ad9cd815b63fc1a753df2eb76"
   },
   "outputs": [],
   "source": [
    "df_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "15ba9792e6a370b7560330af15b3cfe21185c1cb"
   },
   "outputs": [],
   "source": [
    "y = df_data['label']\n",
    "\n",
    "df_train, df_val = train_test_split(df_data, test_size=0.10, random_state=101, stratify=y)\n",
    "\n",
    "print(df_train.shape)\n",
    "print(df_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "7de70d915a5f1d2599725e00bdb3b9103d947883"
   },
   "outputs": [],
   "source": [
    "df_train['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "392c0eea00be8e43a6e55438d1458650e842030b"
   },
   "outputs": [],
   "source": [
    "df_val['label'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "ba17dd34b75367fc61df6634d51dac94c3ab4951"
   },
   "source": [
    "### Create a Directory Structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "_uuid": "ff8acc2e92a1b1b5002d6e1bf9a1180c3256f19d"
   },
   "outputs": [],
   "source": [
    "base_dir = 'base_dir'\n",
    "os.mkdir(base_dir)\n",
    "\n",
    "\n",
    "train_dir = os.path.join(base_dir, 'train_dir')\n",
    "os.mkdir(train_dir)\n",
    "\n",
    "\n",
    "val_dir = os.path.join(base_dir, 'val_dir')\n",
    "os.mkdir(val_dir)\n",
    "\n",
    "\n",
    "no_met_tissue = os.path.join(train_dir, 'a_no_met_tissue')\n",
    "os.mkdir(no_met_tissue)\n",
    "has_met_tissue = os.path.join(train_dir, 'b_has_met_tissue')\n",
    "os.mkdir(has_met_tissue)\n",
    "\n",
    "\n",
    "no_met_tissue = os.path.join(val_dir, 'a_no_met_tissue')\n",
    "os.mkdir(no_met_tissue)\n",
    "has_met_tissue = os.path.join(val_dir, 'b_has_met_tissue')\n",
    "os.mkdir(has_met_tissue)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "03ca5d4b8b027c2712d7096314d3a79ef829b23c"
   },
   "outputs": [],
   "source": [
    "# check that the folders have been created\n",
    "os.listdir('base_dir/train_dir')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "6a2e56340ba18f3b63c1b129fd995fecfadaa21d"
   },
   "source": [
    "### Transfer the images into the folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "e84c8a9642b030094b1888af3299063f883112a6"
   },
   "outputs": [],
   "source": [
    "df_data.set_index('id', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "_uuid": "afb8969a9ee75c13bddc808a4bcc326611baaaaf"
   },
   "outputs": [],
   "source": [
    "train_list = list(df_train['id'])\n",
    "val_list = list(df_val['id'])\n",
    "\n",
    "\n",
    "\n",
    "for image in train_list:\n",
    "    \n",
    "    fname_tif = image + '.tif'\n",
    "    target = df_data.loc[image,'label']\n",
    "    \n",
    "    if target == 0:\n",
    "        label = 'a_no_met_tissue'\n",
    "    if target == 1:\n",
    "        label = 'b_has_met_tissue'\n",
    "    \n",
    "    src = os.path.join('../input/histopathologic-cancer-detection/train', fname_tif)\n",
    "    fname_png = image + '.png'\n",
    "    dst = os.path.join(train_dir, label, fname_png)\n",
    "\n",
    "    \n",
    "    cv2_image = cv2.imread(src)\n",
    "    cv2.imwrite(dst, cv2_image)\n",
    " \n",
    "\n",
    "\n",
    "# Transfer the val images\n",
    "\n",
    "for image in val_list:\n",
    "    \n",
    "\n",
    "    fname_tif = image + '.tif'\n",
    "    target = df_data.loc[image,'label']\n",
    "    \n",
    "    if target == 0:\n",
    "        label = 'a_no_met_tissue'\n",
    "    if target == 1:\n",
    "        label = 'b_has_met_tissue'\n",
    "    \n",
    "\n",
    "\n",
    "    src = os.path.join('../input/histopathologic-cancer-detection/train', fname_tif)\n",
    "    fname_png = image + '.png'\n",
    "    dst = os.path.join(val_dir, label, fname_png)\n",
    "\n",
    "    \n",
    "\n",
    "    cv2_image = cv2.imread(src)\n",
    "    cv2.imwrite(dst, cv2_image)\n",
    "\n",
    "\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "71532bfc32608289b1f773ffdbc8a7cea1bfb94c"
   },
   "outputs": [],
   "source": [
    "print(len(os.listdir('base_dir/train_dir/a_no_met_tissue')))\n",
    "print(len(os.listdir('base_dir/train_dir/b_has_met_tissue')))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "897e9df543bb65b47bb00019dc681125ca08ee5d"
   },
   "outputs": [],
   "source": [
    "print(len(os.listdir('base_dir/val_dir/a_no_met_tissue')))\n",
    "print(len(os.listdir('base_dir/val_dir/b_has_met_tissue')))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "ef780ac9a9fc89b4ff4f042593eb68992f354a1d"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "f8dce940ee8a7a42aacb062e4c6b5a4a54dba58f"
   },
   "source": [
    "### Set Up the Generators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "ef4fe7be09f11ff4badfd22d5fd5e03f8521ed58"
   },
   "outputs": [],
   "source": [
    "train_path = 'base_dir/train_dir'\n",
    "valid_path = 'base_dir/val_dir'\n",
    "test_path = '../input/test'\n",
    "\n",
    "num_train_samples = len(df_train)\n",
    "num_val_samples = len(df_val)\n",
    "train_batch_size = 10\n",
    "val_batch_size = 10\n",
    "\n",
    "\n",
    "train_steps = np.ceil(num_train_samples / train_batch_size)\n",
    "val_steps = np.ceil(num_val_samples / val_batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "68fbd9d5fbb80859a82f94a12e335ce05a93bd51"
   },
   "outputs": [],
   "source": [
    "datagen = ImageDataGenerator(rescale=1.0/255)\n",
    "\n",
    "train_gen = datagen.flow_from_directory(train_path,\n",
    "                                        target_size=(IMAGE_SIZE,IMAGE_SIZE),\n",
    "                                        batch_size=train_batch_size,\n",
    "                                        class_mode='categorical')\n",
    "\n",
    "val_gen = datagen.flow_from_directory(valid_path,\n",
    "                                        target_size=(IMAGE_SIZE,IMAGE_SIZE),\n",
    "                                        batch_size=val_batch_size,\n",
    "                                        class_mode='categorical')\n",
    "\n",
    "\n",
    "test_gen = datagen.flow_from_directory(valid_path,\n",
    "                                        target_size=(IMAGE_SIZE,IMAGE_SIZE),\n",
    "                                        batch_size=1,\n",
    "                                        class_mode='categorical',\n",
    "                                        shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "79da4d0a66a90cffe40580a596dd4d0e2bc45a9b"
   },
   "source": [
    "### Create the Model Architecture¶"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-output": true,
    "_uuid": "b9835ea0fd0bca54138904895c39d38227a70c22"
   },
   "outputs": [],
   "source": [
    "kernel_size = (3,3)\n",
    "pool_size= (2,2)\n",
    "first_filters = 32\n",
    "second_filters = 64\n",
    "third_filters = 128\n",
    "\n",
    "dropout_conv = 0.3\n",
    "dropout_dense = 0.3\n",
    "\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(first_filters, kernel_size, activation = 'relu', input_shape = (96, 96, 3)))\n",
    "model.add(Conv2D(first_filters, kernel_size, activation = 'relu'))\n",
    "model.add(Conv2D(first_filters, kernel_size, activation = 'relu'))\n",
    "model.add(MaxPooling2D(pool_size = pool_size)) \n",
    "model.add(Dropout(dropout_conv))\n",
    "\n",
    "model.add(Conv2D(second_filters, kernel_size, activation ='relu'))\n",
    "model.add(Conv2D(second_filters, kernel_size, activation ='relu'))\n",
    "model.add(Conv2D(second_filters, kernel_size, activation ='relu'))\n",
    "model.add(MaxPooling2D(pool_size = pool_size))\n",
    "model.add(Dropout(dropout_conv))\n",
    "\n",
    "model.add(Conv2D(third_filters, kernel_size, activation ='relu'))\n",
    "model.add(Conv2D(third_filters, kernel_size, activation ='relu'))\n",
    "model.add(Conv2D(third_filters, kernel_size, activation ='relu'))\n",
    "model.add(MaxPooling2D(pool_size = pool_size))\n",
    "model.add(Dropout(dropout_conv))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(256, activation = \"relu\"))\n",
    "model.add(Dropout(dropout_dense))\n",
    "model.add(Dense(2, activation = \"softmax\"))\n",
    "\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "75cfc4fcb8dd3408d1c4fcf8cd85e0e2f5b611d7"
   },
   "source": [
    "### Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "9de9715f49a63b55775b10abd2f461b395e23b5d"
   },
   "outputs": [],
   "source": [
    "model.compile(Adam(lr=0.0001), loss='binary_crossentropy', \n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "227d84a4f44c0b7256855c06ba04dabd58d89d84"
   },
   "outputs": [],
   "source": [
    "print(val_gen.class_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "a746769db61563f226288eba9aa8a6584b9e8e0b",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "filepath = \"model.h5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_acc', verbose=1, \n",
    "                             save_best_only=True, mode='max')\n",
    "\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_acc', factor=0.5, patience=2, \n",
    "                                   verbose=1, mode='max', min_lr=0.00001)\n",
    "                              \n",
    "                              \n",
    "callbacks_list = [checkpoint, reduce_lr]\n",
    "\n",
    "history = model.fit_generator(train_gen, steps_per_epoch=train_steps, \n",
    "                    validation_data=val_gen,\n",
    "                    validation_steps=val_steps,\n",
    "                    epochs=20, verbose=1,\n",
    "                   callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "fa15a8afda3593973726e9087cbd98073041c908"
   },
   "source": [
    "### Evaluate the model using the val set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "70104420ec7f400cd06203f875dbeba30f4d8a96"
   },
   "outputs": [],
   "source": [
    "model.metrics_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "428bdf5b24ff8cef35012205c3f2eb37006fc9e9"
   },
   "outputs": [],
   "source": [
    "model.load_weights('model.h5')\n",
    "\n",
    "val_loss, val_acc = \\\n",
    "model.evaluate_generator(test_gen, \n",
    "                        steps=len(df_val))\n",
    "\n",
    "print('val_loss:', val_loss)\n",
    "print('val_acc:', val_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "93556c9e4b6a188cf9cb67a6519c9bc365c60caf"
   },
   "source": [
    "### Plot the Training Curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "_uuid": "385da8ba94a1079d17909790716b295fc2737584"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "acc = history.history['acc']\n",
    "val_acc = history.history['val_acc']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs = range(1, len(acc) + 1)\n",
    "\n",
    "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.legend()\n",
    "plt.figure()\n",
    "\n",
    "plt.plot(epochs, acc, 'bo', label='Training acc')\n",
    "plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.legend()\n",
    "plt.figure()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "5636e76f23202dd1f2a27ace25e15e09619a5e4e"
   },
   "source": [
    "### Make a prediction on the val set\n",
    "We need these predictions to calculate the AUC score, print the Confusion Matrix and calculate the F1 score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "652d9d6aa51dc1818d1c5171212d10e141ad7de9"
   },
   "outputs": [],
   "source": [
    "predictions = model.predict_generator(test_gen, steps=len(df_val), verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "edf1866df4638ded26de2e0e3d2ba0f5e00e1ace"
   },
   "outputs": [],
   "source": [
    "predictions.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "6bbf4f095fe5412561924c09c96d8dc2ea4adfc0"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "dc71f69944e7db83329417c5265a5bc31f9c4fc3"
   },
   "outputs": [],
   "source": [
    " test_gen.class_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "4a6709d73969f7fd597128223b110be077f84edb"
   },
   "outputs": [],
   "source": [
    "df_preds = pd.DataFrame(predictions, columns=['no_met_tissue', 'has_met_tissue'])\n",
    "\n",
    "df_preds.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "0954d61a4ef8bc056452b3bbad9456d45c00bed1"
   },
   "outputs": [],
   "source": [
    "y_true = test_gen.classes\n",
    "\n",
    "y_pred = df_preds['has_met_tissue']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "f07c814d213e814cdac4e3d05d0a8db847fbfe28"
   },
   "source": [
    "### What is the AUC Score?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "0b7b7a56c6fa47cc40764d0c06d64860580cbea1"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "roc_auc_score(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "9d8404e8e6b6008c8989b8184700ec5562b99366"
   },
   "source": [
    "### Create a Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true,
    "_uuid": "91f570e8e5f07126e5361bbf92929d786e853a09"
   },
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    print(cm)\n",
    "\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "c20bc358dc753020d5a560dc56f2350c7f40a4f9"
   },
   "outputs": [],
   "source": [
    "test_labels = test_gen.classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "3a537724473df19c74bb1bf6928f531dd0fcfdb3"
   },
   "outputs": [],
   "source": [
    "test_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "0bb4323e931ff53081994bbf58e82b1ec93ab327"
   },
   "outputs": [],
   "source": [
    "cm = confusion_matrix(test_labels, predictions.argmax(axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "ec2058223eb30485898a12c0e904bb170c0aa884"
   },
   "outputs": [],
   "source": [
    "test_gen.class_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "ba26c7e718df937a18aa2035c4ba883252e44c79"
   },
   "outputs": [],
   "source": [
    "cm_plot_labels = ['no_met_tissue', 'has_met_tissue']\n",
    "\n",
    "plot_confusion_matrix(cm, cm_plot_labels, title='Confusion Matrix')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "2576c1144cfe93d66f3197396990f3e43addd499"
   },
   "source": [
    "### Create a Classification Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "91dcace7eb99aca310774b7a3a55535c9127ce55"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "y_pred_binary = predictions.argmax(axis=1)\n",
    "\n",
    "report = classification_report(y_true, y_pred_binary, target_names=cm_plot_labels)\n",
    "\n",
    "print(report)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "36880545abb112946ebe48242d5da6c8517cf61b"
   },
   "source": [
    "**Recall**= Given a class, will the classifier be able to detect it?<br>\n",
    "**Precision**= Given a class prediction from a classifier, how likely is it to be correct?<br>\n",
    "**F1 Score** = The harmonic mean of the recall and precision. Essentially, it punishes extreme values.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "4b0b4f6065e0ba97d9170cc6d9e23ae3d064a73e"
   },
   "source": [
    "### Convert the model to from Keras to Tensorflowjs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "1510fc5dedb309e4b03c6cbee3acf27f55739ecc"
   },
   "outputs": [],
   "source": [
    "shutil.rmtree('base_dir')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-output": true,
    "_uuid": "28dd1e74473a0523885e50e8d17fd7d50036d9df"
   },
   "outputs": [],
   "source": [
    "!pip install tensorflowjs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "d565698d4fd2e7479bb0331bf9c9c73fd97fb64d"
   },
   "outputs": [],
   "source": [
    "!tensorflowjs_converter --input_format keras model.h5 tfjs_model_2/model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "eb92189bf34d85d3e5088803fc170297456da902"
   },
   "source": [
    "\n",
    "### Resources\n",
    "\n",
    "Resourese i used for this project :\n",
    "\n",
    "1. Gabriel Preda, Honey Bee Subspecies Classification <br>\n",
    "https://www.kaggle.com/gpreda/honey-bee-subspecies-classification<br>\n",
    "\n",
    "2. Beluga, Black and White CNN<br>\n",
    "https://www.kaggle.com/gaborfodor/black-white-cnn-lb-0-77\n",
    "\n",
    "3.  Francesco Marazzi, Baseline Keras CNN<br>\n",
    "https://www.kaggle.com/fmarazzi/baseline-keras-cnn-roc-fast-5min-0-8253-lb\n",
    "\n",
    "4. YouTube tutorial by deeplizard on how to use Tensorflowjs<br>\n",
    "https://www.youtube.com/watch?v=HEQDRWMK6yY\n",
    "\n",
    "5. Tutorial by jenkov.com explaining the HTML5 File API<br>\n",
    "http://tutorials.jenkov.com/html5/file-api.html\n",
    "\n",
    "6. Blog post by Anton Lavrenov on how to handle async/await<br>\n",
    "https://blog.lavrton.com/javascript-loops-how-to-handle-async-await-6252dd3c795\n",
    "\n",
    "7. jQuery tutorial by W3Schools<br>\n",
    "https://www.w3schools.com/jquery/default.asp\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "2b21291a024b887cef5d17f324c5dc4503f2a0fb"
   },
   "source": [
    "### Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "608870cf40209fac3b55b7af4c972293fd7c8b80"
   },
   "source": [
    "All the html, css, and javascript code used to build the web app is available on Github. \n",
    "\n",
    "Live web app:<br>\n",
    "<br>\n",
    "Github:<br>\n",
    "https://github.com/MalshaRajapaksha/Breast-Cancer-Detector\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
